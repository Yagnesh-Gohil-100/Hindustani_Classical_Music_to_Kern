{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroup Range: (4, 7)\n",
      "Kann Swar List: [[], [], [], [], [], [], [], [], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row4_col12_x400_y145_w7_h10.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row4_col13_x434_y145_w9_h10.png'], []]\n",
      "Swar List: [[], [], [], [], [], [], [], [], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row5_col12_x406_y162_w10_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row5_col13_x439_y162_w10_h14.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row5_col14_x472_y166_w9_h5.png']]\n",
      "Swar Articulation Checks: [[], [], [], [], [], [], [], [], [], [], [], False, False, False]\n",
      "Lyrics List: [[], [], [], [], [], [], [], [], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row6_col12_x405_y188_w11_h15.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row6_col13_x436_y188_w14_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row6_col14_x473_y187_w8_h12.png']]\n",
      "Lyrics Articulation Checks: [[], [], [], [], [], [], [], [], [], [], [], False, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (7, 8)\n",
      "Kann Swar List: [[], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col3_x156_y211_w14_h12.png'], [], [], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col9_x303_y213_w8_h8.png'], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col12_x401_y211_w13_h10.png'], [], []]\n",
      "Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row7_col1_x118_y231_w9_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col2_x139_y236_w9_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col3_x159_y227_w14_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col4_x181_y214_w17_h29.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col5_x215_y227_w15_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col6_x240_y235_w10_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col7_x260_y235_w11_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col8_x281_y226_w14_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col9_x304_y226_w14_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col10_x339_y227_w15_h15.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col11_x376_y235_w9_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col12_x405_y225_w7_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col13_x434_y226_w15_h15.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col14_x470_y234_w10_h4.png']]\n",
      "Swar Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "Lyrics List: [['Analysis\\\\bilawal_dhamaar\\\\0_row8_col1_x118_y256_w12_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col2_x141_y260_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col3_x163_y260_w9_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col4_x184_y260_w11_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col5_x215_y259_w13_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col6_x242_y259_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col7_x263_y259_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col8_x285_y258_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col9_x310_y259_w9_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col10_x339_y252_w14_h19.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col11_x375_y258_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col12_x406_y258_w8_h14.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col13_x441_y258_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col14_x473_y257_w7_h13.png']]\n",
      "Lyrics Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (10, 14)\n",
      "Kann Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row10_col1_x116_y294_w14_h13.png'], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row10_col5_x213_y296_w6_h9.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row10_col6_x232_y296_w7_h9.png'], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row10_col8_x278_y295_w9_h9.png'], [], [], [], [], [], []]\n",
      "Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row11_col1_x117_y314_w10_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col2_x137_y309_w22_h23.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col3_x169_y313_w8_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col4_x189_y318_w9_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col5_x215_y312_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col6_x235_y313_w10_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col7_x255_y307_w15_h14.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col8_x285_y312_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col9_x309_y312_w9_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col10_x338_y312_w9_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col11_x367_y311_w18_h9.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col12_x405_y312_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col13_x437_y305_w8_h19.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col14_x471_y316_w10_h4.png']]\n",
      "Swar Articulation Checks: [False, False, False, False, False, False, True, False, False, False, True, False, False, False]\n",
      "Lyrics List: [['Analysis\\\\bilawal_dhamaar\\\\0_row13_col1_x117_y343_w11_h14.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col2_x137_y337_w20_h15.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col3_x165_y342_w15_h14.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col4_x190_y342_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col5_x215_y342_w10_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col6_x234_y342_w9_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col7_x256_y341_w13_h10.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col8_x282_y342_w15_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col9_x311_y341_w7_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col10_x338_y342_w11_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col11_x367_y340_w15_h19.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col12_x405_y341_w9_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col13_x436_y341_w9_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col14_x473_y340_w7_h12.png']]\n",
      "Lyrics Articulation Checks: [False, True, False, False, False, False, True, False, False, False, False, False, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (16, 19)\n",
      "Kann Swar List: [[], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row16_col5_x213_y374_w12_h14.png'], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row16_col9_x273_y376_w14_h12.png'], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row16_col14_x399_y377_w6_h10.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row16_col15_x438_y377_w9_h10.png'], []]\n",
      "Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row18_col1_x116_y395_w15_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col2_x142_y400_w10_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col3_x162_y400_w11_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col4_x183_y395_w15_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col5_x215_y392_w14_h15.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col7_x239_y391_w15_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col8_x263_y399_w10_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col10_x284_y395_w10_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col11_x308_y399_w9_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col12_x338_y391_w13_h19.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col13_x372_y394_w9_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col14_x404_y394_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col15_x437_y394_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col17_x468_y399_w12_h4.png']]\n",
      "Swar Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "Lyrics List: [['Analysis\\\\bilawal_dhamaar\\\\0_row19_col1_x115_y418_w15_h18.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col2_x141_y423_w7_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col3_x165_y423_w8_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col4_x183_y424_w11_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col5_x214_y420_w9_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col7_x237_y423_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col8_x263_y423_w7_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col10_x288_y424_w9_h14.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col11_x310_y423_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col12_x338_y423_w7_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col13_x367_y424_w13_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col14_x402_y417_w13_h22.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col15_x432_y423_w13_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col16_x463_y423_w8_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col18_x478_y423_w5_h14.png']]\n",
      "Lyrics Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (22, 24)\n",
      "Kann Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row22_col1_x114_y477_w12_h14.png'], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row22_col6_x173_y478_w13_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row22_col7_x194_y481_w9_h10.png'], [], [], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row22_col14_x397_y477_w12_h13.png'], [], [], []]\n",
      "Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row23_col1_x115_y495_w14_h15.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col2_x137_y502_w10_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col4_x158_y502_w10_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col6_x179_y494_w14_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col8_x204_y493_w14_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col9_x239_y494_w15_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col10_x275_y502_w9_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col11_x306_y493_w15_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col12_x336_y503_w9_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col13_x364_y494_w15_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col14_x403_y494_w15_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col15_x424_y493_w8_h18.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col16_x442_y493_w15_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col17_x467_y502_w12_h4.png']]\n",
      "Swar Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "Lyrics List: [['Analysis\\\\bilawal_dhamaar\\\\0_row24_col1_x115_y527_w13_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col3_x143_y526_w8_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col5_x164_y526_w8_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col6_x185_y527_w10_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col8_x209_y527_w9_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col9_x238_y527_w14_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col10_x274_y526_w8_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col11_x304_y527_w12_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col12_x337_y527_w8_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col13_x369_y527_w11_h15.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col14_x403_y522_w9_h21.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col15_x423_y526_w7_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col16_x449_y527_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col17_x471_y526_w8_h12.png']]\n",
      "Lyrics Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (26, 27)\n",
      "Kann Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row26_col1_x113_y560_w13_h13.png'], [], [], [], [], [], [], [], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col12_x397_y560_w12_h13.png'], [], [], []]\n",
      "Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row26_col1_x114_y577_w15_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col2_x140_y576_w10_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col3_x161_y585_w9_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col4_x179_y558_w8_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col5_x185_y576_w10_h18.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col6_x208_y585_w10_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col7_x238_y585_w10_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col8_x274_y577_w10_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col9_x300_y561_w12_h31.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col10_x337_y585_w10_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col11_x368_y585_w12_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col12_x402_y576_w15_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col13_x424_y575_w7_h18.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col14_x441_y575_w15_h18.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col15_x463_y576_w15_h17.png']]\n",
      "Swar Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "Lyrics List: [['Analysis\\\\bilawal_dhamaar\\\\0_row27_col1_x114_y604_w13_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col2_x142_y609_w8_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col3_x160_y608_w8_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col5_x186_y610_w9_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col6_x210_y609_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col7_x238_y609_w8_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col8_x274_y609_w10_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col9_x304_y609_w9_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col10_x341_y609_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col11_x372_y609_w7_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col12_x402_y603_w10_h18.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col13_x427_y609_w7_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col14_x446_y609_w9_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col15_x470_y608_w8_h14.png']]\n",
      "Lyrics Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (29, 33)\n",
      "Kann Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row29_col1_x112_y645_w10_h10.png'], [], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row29_col6_x233_y645_w10_h9.png'], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row29_col8_x298_y646_w7_h10.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row29_col10_x332_y646_w9_h10.png'], [], [], [], [], []]\n",
      "Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row30_col1_x113_y663_w11_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col2_x133_y658_w21_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col3_x163_y657_w8_h19.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col4_x181_y658_w15_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col5_x203_y658_w15_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col6_x239_y663_w10_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col7_x265_y658_w19_h14.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col8_x303_y662_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col10_x336_y662_w11_h14.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col11_x370_y667_w10_h4.png'], [], [], [], []]\n",
      "Swar Articulation Checks: [False, True, False, False, False, False, True, False, False, False, False, False, False, False]\n",
      "Lyrics List: [['Analysis\\\\bilawal_dhamaar\\\\0_row32_col1_x113_y688_w15_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col2_x138_y691_w13_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col3_x167_y692_w7_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col4_x185_y692_w12_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col5_x207_y692_w10_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col6_x238_y691_w15_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col7_x270_y690_w13_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col8_x304_y691_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col10_x334_y691_w14_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col11_x371_y691_w8_h12.png'], [], [], [], []]\n",
      "Lyrics Articulation Checks: [False, True, False, False, False, False, True, False, False, False, False, False, False, False]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# same code as above but storing image paths in lists for direct access\n",
    "\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the path to the folder containing the images\n",
    "image_folder_path = 'Analysis/bilawal_dhamaar'\n",
    "\n",
    "# Define the section-wise row numbers\n",
    "articulation_rows = [12, 14, 31, 33]\n",
    "kann_swar_rows = [4, 10, 16, 22, 29]\n",
    "swar_rows = [5, 7, 11, 18, 23, 26, 30]\n",
    "lyrics_rows = [6, 8, 13, 19, 24, 27, 32]\n",
    "\n",
    "# Define the subgroup ranges\n",
    "subgroup_ranges = [\n",
    "    (4, 7),\n",
    "    (7, 8),\n",
    "    (10, 14),\n",
    "    (16, 19),\n",
    "    (22, 24),\n",
    "    (26, 27),\n",
    "    (29, 33)\n",
    "]\n",
    "\n",
    "# Define the beat count (size of the lists)\n",
    "beat_count = 14\n",
    "\n",
    "# Function to extract information from the image filename\n",
    "def extract_info_from_filename(filename):\n",
    "    pattern = r'(\\d+)_row(\\d+)(?:_col(\\d+))?_x(\\d+)_y(\\d+)_w(\\d+)_h(\\d+)'\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        page_num = int(match.group(1))\n",
    "        row_num = int(match.group(2))\n",
    "        col_num = int(match.group(3)) if match.group(3) else None\n",
    "        x = int(match.group(4))\n",
    "        y = int(match.group(5))\n",
    "        width = int(match.group(6))\n",
    "        height = int(match.group(7))\n",
    "        # Use os.path.join to handle path separators correctly\n",
    "        image_path = os.path.normpath(os.path.join(image_folder_path, filename))\n",
    "        return page_num, row_num, col_num, x, y, width, height, image_path\n",
    "    return None\n",
    "\n",
    "# Load all image filenames and extract their information\n",
    "image_files = os.listdir(image_folder_path)\n",
    "image_info = [extract_info_from_filename(f) for f in image_files]\n",
    "image_info = [info for info in image_info if info is not None]\n",
    "\n",
    "# Organize images by row and column\n",
    "row_col_images = defaultdict(lambda: defaultdict(list))\n",
    "for info in image_info:\n",
    "    page_num, row_num, col_num, x, y, width, height, image_path = info\n",
    "    row_col_images[row_num][col_num].append((x, y, width, height, image_path))\n",
    "\n",
    "# Function to pad lists to match the beat count\n",
    "def pad_lists(lists, size):\n",
    "    if len(lists) < size:\n",
    "        padding = [[] for _ in range(size - len(lists))]\n",
    "        return padding + lists\n",
    "    return lists\n",
    "\n",
    "# Function to process a subgroup and create the lists of lists\n",
    "def process_subgroup(subgroup_range, is_first_subgroup):\n",
    "    start_row, end_row = subgroup_range\n",
    "    \n",
    "    # Find the swar row in this subgroup\n",
    "    swar_row = None\n",
    "    for row in swar_rows:\n",
    "        if start_row <= row <= end_row:\n",
    "            swar_row = row\n",
    "            break\n",
    "    \n",
    "    if not swar_row:\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    # Find the kann swar row in this subgroup\n",
    "    kann_swar_row = None\n",
    "    for row in kann_swar_rows:\n",
    "        if start_row <= row <= end_row:\n",
    "            kann_swar_row = row\n",
    "            break\n",
    "    \n",
    "    # Find the articulation rows in this subgroup\n",
    "    articulation_rows_in_subgroup = [row for row in articulation_rows if start_row <= row <= end_row]\n",
    "    \n",
    "    # Find the lyrics row in this subgroup\n",
    "    lyrics_row = None\n",
    "    for row in lyrics_rows:\n",
    "        if start_row <= row <= end_row:\n",
    "            lyrics_row = row\n",
    "            break\n",
    "    \n",
    "    # Get the swar images and their column numbers\n",
    "    swar_images = row_col_images[swar_row]\n",
    "    swar_cols = sorted(swar_images.keys())\n",
    "    \n",
    "    # Get the kann swar images and their column numbers (if kann swar row exists)\n",
    "    kann_swar_images = row_col_images[kann_swar_row] if kann_swar_row else {}\n",
    "    kann_swar_cols = sorted(kann_swar_images.keys())\n",
    "    \n",
    "    # Get the lyrics images (if lyrics row exists)\n",
    "    lyrics_images = row_col_images[lyrics_row] if lyrics_row else {}\n",
    "    lyrics_cols = sorted(lyrics_images.keys()) if lyrics_row else []\n",
    "    \n",
    "    # Create the lists of lists\n",
    "    swar_list = []\n",
    "    kann_swar_list = []\n",
    "    swar_articulation_checks = [False] * len(swar_cols)\n",
    "    lyrics_articulation_checks = [False] * len(lyrics_cols)\n",
    "    lyrics_list = []\n",
    "    \n",
    "    # Case 1: If there is an explicit kann swar row\n",
    "    if kann_swar_row:\n",
    "        swar_index = 0\n",
    "        kann_swar_index = 0\n",
    "        \n",
    "        while swar_index < len(swar_cols) or kann_swar_index < len(kann_swar_cols):\n",
    "            swar_col = swar_cols[swar_index] if swar_index < len(swar_cols) else None\n",
    "            kann_swar_col = kann_swar_cols[kann_swar_index] if kann_swar_index < len(kann_swar_cols) else None\n",
    "            \n",
    "            # If both columns exist and match\n",
    "            if swar_col is not None and kann_swar_col is not None and swar_col == kann_swar_col:\n",
    "                swar_list.append([x[4] for x in swar_images[swar_col]])  # Store image paths\n",
    "                kann_swar_list.append([x[4] for x in kann_swar_images[kann_swar_col]])  # Store image paths\n",
    "                swar_index += 1\n",
    "                kann_swar_index += 1\n",
    "            # If swar column exists but kann swar column doesn't match or is missing\n",
    "            elif swar_col is not None and (kann_swar_col is None or swar_col < kann_swar_col):\n",
    "                swar_list.append([x[4] for x in swar_images[swar_col]])  # Store image paths\n",
    "                kann_swar_list.append([])\n",
    "                swar_index += 1\n",
    "            # If kann swar column exists but swar column doesn't match or is missing\n",
    "            elif kann_swar_col is not None and (swar_col is None or kann_swar_col < swar_col):\n",
    "                # Assign the kann swar to the next available swar column\n",
    "                if swar_index < len(swar_cols):\n",
    "                    swar_list.append([x[4] for x in swar_images[swar_cols[swar_index]]])  # Store image paths\n",
    "                    kann_swar_list.append([x[4] for x in kann_swar_images[kann_swar_col]])  # Store image paths\n",
    "                    swar_index += 1\n",
    "                    kann_swar_index += 1\n",
    "                else:\n",
    "                    # If no more swar columns are available, append an empty list\n",
    "                    swar_list.append([])\n",
    "                    kann_swar_list.append([x[4] for x in kann_swar_images[kann_swar_col]])  # Store image paths\n",
    "                    kann_swar_index += 1\n",
    "    \n",
    "    # Case 2: If there is no explicit kann swar row, check for hidden kann swars in the swar row\n",
    "    else:\n",
    "        for col in swar_cols:\n",
    "            images_in_col = swar_images[col]\n",
    "            if len(images_in_col) == 1:\n",
    "                # Only one image in this column, so no hidden kann swar\n",
    "                swar_list.append([images_in_col[0][4]])  # Store image path\n",
    "                kann_swar_list.append([])\n",
    "            else:\n",
    "                # Multiple images in the same column, so identify hidden kann swars\n",
    "                # Sort images by y-value (lower y-value is kann swar)\n",
    "                sorted_images = sorted(images_in_col, key=lambda x: x[1])  # Sort by y-value\n",
    "                kann_swar_list.append([sorted_images[0][4]])  # Lower y-value is kann swar (store image path)\n",
    "                swar_list.append([sorted_images[1][4]])  # Higher y-value is swar (store image path)\n",
    "    \n",
    "    # Handle articulation rows\n",
    "    for articulation_row in articulation_rows_in_subgroup:\n",
    "        # Find the row just before the articulation row\n",
    "        prev_row = articulation_row - 1\n",
    "        if prev_row in swar_rows:\n",
    "            # Swar articulation\n",
    "            articulation_images = row_col_images[articulation_row]\n",
    "            articulation_cols = sorted(articulation_images.keys())\n",
    "            for i, col in enumerate(swar_cols):\n",
    "                if col in articulation_cols:\n",
    "                    swar_articulation_checks[i] = True\n",
    "        elif prev_row in lyrics_rows:\n",
    "            # Lyrics articulation\n",
    "            articulation_images = row_col_images[articulation_row]\n",
    "            articulation_cols = sorted(articulation_images.keys())\n",
    "            for i, col in enumerate(swar_cols):\n",
    "                if col in articulation_cols:\n",
    "                    lyrics_articulation_checks[i] = True\n",
    "    \n",
    "    # Handle lyrics row (append images one by one without comparing column numbers)\n",
    "    if lyrics_row:\n",
    "        # Get all lyrics images in order\n",
    "        lyrics_cols = sorted(lyrics_images.keys())\n",
    "        for col in lyrics_cols:\n",
    "            lyrics_list.append([x[4] for x in lyrics_images[col]])  # Store image paths\n",
    "    else:\n",
    "        lyrics_list = [[] for _ in range(len(swar_cols))]\n",
    "    \n",
    "    # Pad lists to match the beat count\n",
    "    if is_first_subgroup:\n",
    "        swar_list = pad_lists(swar_list, beat_count)\n",
    "        kann_swar_list = pad_lists(kann_swar_list, beat_count)\n",
    "        swar_articulation_checks = pad_lists(swar_articulation_checks, beat_count)\n",
    "        lyrics_articulation_checks = pad_lists(lyrics_articulation_checks, beat_count)\n",
    "        lyrics_list = pad_lists(lyrics_list, beat_count)\n",
    "    else:\n",
    "        if len(swar_list) < beat_count:\n",
    "            swar_list += [[] for _ in range(beat_count - len(swar_list))]\n",
    "        if len(kann_swar_list) < beat_count:\n",
    "            kann_swar_list += [[] for _ in range(beat_count - len(kann_swar_list))]\n",
    "        if len(swar_articulation_checks) < beat_count:\n",
    "            swar_articulation_checks += [False for _ in range(beat_count - len(swar_articulation_checks))]\n",
    "        if len(lyrics_articulation_checks) < beat_count:\n",
    "            lyrics_articulation_checks += [False for _ in range(beat_count - len(lyrics_articulation_checks))]\n",
    "        if len(lyrics_list) < beat_count:\n",
    "            lyrics_list += [[] for _ in range(beat_count - len(lyrics_list))]\n",
    "    \n",
    "    return swar_list, kann_swar_list, swar_articulation_checks, lyrics_articulation_checks, lyrics_list\n",
    "\n",
    "# Process each subgroup and store the results\n",
    "subgroup_results = {}\n",
    "for i, subgroup_range in enumerate(subgroup_ranges):\n",
    "    is_first_subgroup = (i == 0)\n",
    "    swar_list, kann_swar_list, swar_articulation_checks, lyrics_articulation_checks, lyrics_list = process_subgroup(subgroup_range, is_first_subgroup)\n",
    "    if swar_list and kann_swar_list:\n",
    "        subgroup_results[subgroup_range] = {\n",
    "            'swar_list': swar_list,\n",
    "            'kann_swar_list': kann_swar_list,\n",
    "            'swar_articulation_checks': swar_articulation_checks,\n",
    "            'lyrics_articulation_checks': lyrics_articulation_checks,\n",
    "            'lyrics_list': lyrics_list\n",
    "        }\n",
    "\n",
    "# Print the results for each subgroup\n",
    "for subgroup_range, results in subgroup_results.items():\n",
    "    print(f\"Subgroup Range: {subgroup_range}\")\n",
    "    print(f\"Kann Swar List: {results['kann_swar_list']}\")\n",
    "    print(f\"Swar List: {results['swar_list']}\")\n",
    "    print(f\"Swar Articulation Checks: {results['swar_articulation_checks']}\")\n",
    "    print(f\"Lyrics List: {results['lyrics_list']}\")\n",
    "    print(f\"Lyrics Articulation Checks: {results['lyrics_articulation_checks']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroup Range: (4, 7)\n",
      "Kann Swar List: [[], [], [], [], [], [], [], [], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row4_col12_x400_y145_w7_h10.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row4_col13_x434_y145_w9_h10.png'], []]\n",
      "Swar List: [[], [], [], [], [], [], [], [], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row5_col12_x406_y162_w10_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row5_col13_x439_y162_w10_h14.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row5_col14_x472_y166_w9_h5.png']]\n",
      "Lyrics List: [[], [], [], [], [], [], [], [], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row6_col12_x405_y188_w11_h15.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row6_col13_x436_y188_w14_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row6_col14_x473_y187_w8_h12.png']]\n",
      "Swar Articulation Checks: [[], [], [], [], [], [], [], [], [], [], [], False, False, False]\n",
      "Lyrics Articulation Checks: [[], [], [], [], [], [], [], [], [], [], [], False, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (7, 8)\n",
      "Kann Swar List: [[], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col3_x156_y211_w14_h12.png'], [], [], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col9_x303_y213_w8_h8.png'], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col12_x401_y211_w13_h10.png'], [], []]\n",
      "Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row7_col1_x118_y231_w9_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col2_x139_y236_w9_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col3_x159_y227_w14_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col4_x181_y214_w17_h29.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col5_x215_y227_w15_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col6_x240_y235_w10_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col7_x260_y235_w11_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col8_x281_y226_w14_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col9_x304_y226_w14_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col10_x339_y227_w15_h15.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col11_x376_y235_w9_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col12_x405_y225_w7_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col13_x434_y226_w15_h15.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row7_col14_x470_y234_w10_h4.png']]\n",
      "Lyrics List: [['Analysis\\\\bilawal_dhamaar\\\\0_row8_col1_x118_y256_w12_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col2_x141_y260_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col3_x163_y260_w9_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col4_x184_y260_w11_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col5_x215_y259_w13_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col6_x242_y259_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col7_x263_y259_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col8_x285_y258_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col9_x310_y259_w9_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col10_x339_y252_w14_h19.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col11_x375_y258_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col12_x406_y258_w8_h14.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col13_x441_y258_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row8_col14_x473_y257_w7_h13.png']]\n",
      "Swar Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "Lyrics Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (10, 14)\n",
      "Kann Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row10_col1_x116_y294_w14_h13.png'], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row10_col5_x213_y296_w6_h9.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row10_col6_x232_y296_w7_h9.png'], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row10_col8_x278_y295_w9_h9.png'], [], [], [], [], [], []]\n",
      "Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row11_col1_x117_y314_w10_h12.png'], ['Analysis\\\\bilawal_dhamaar_segmented\\\\0_row11_col2_x137_y309_w22_h23_seg1.png', 'Analysis\\\\bilawal_dhamaar_segmented\\\\0_row11_col2_x137_y309_w22_h23_seg2.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col3_x169_y313_w8_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col4_x189_y318_w9_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col5_x215_y312_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col6_x235_y313_w10_h12.png'], ['Analysis\\\\bilawal_dhamaar_segmented\\\\0_row11_col7_x255_y307_w15_h14_seg1.png', 'Analysis\\\\bilawal_dhamaar_segmented\\\\0_row11_col7_x255_y307_w15_h14_seg2.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col8_x285_y312_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col9_x309_y312_w9_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col10_x338_y312_w9_h12.png'], ['Analysis\\\\bilawal_dhamaar_segmented\\\\0_row11_col11_x367_y311_w18_h9_seg1.png', 'Analysis\\\\bilawal_dhamaar_segmented\\\\0_row11_col11_x367_y311_w18_h9_seg2.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col12_x405_y312_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col13_x437_y305_w8_h19.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row11_col14_x471_y316_w10_h4.png']]\n",
      "Lyrics List: [['Analysis\\\\bilawal_dhamaar\\\\0_row13_col1_x117_y343_w11_h14.png'], ['Analysis\\\\bilawal_dhamaar_segmented\\\\0_row13_col2_x137_y337_w20_h15_seg1.png', 'Analysis\\\\bilawal_dhamaar_segmented\\\\0_row13_col2_x137_y337_w20_h15_seg2.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col3_x165_y342_w15_h14.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col4_x190_y342_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col5_x215_y342_w10_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col6_x234_y342_w9_h12.png'], ['Analysis\\\\bilawal_dhamaar_segmented\\\\0_row13_col7_x256_y341_w13_h10_seg1.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col8_x282_y342_w15_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col9_x311_y341_w7_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col10_x338_y342_w11_h11.png'], ['Analysis\\\\bilawal_dhamaar_segmented\\\\0_row13_col11_x367_y340_w15_h19_seg1.png', 'Analysis\\\\bilawal_dhamaar_segmented\\\\0_row13_col11_x367_y340_w15_h19_seg2.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col12_x405_y341_w9_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col13_x436_y341_w9_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row13_col14_x473_y340_w7_h12.png']]\n",
      "Swar Articulation Checks: [False, True, False, False, False, False, True, False, False, False, True, False, False, False]\n",
      "Lyrics Articulation Checks: [False, True, False, False, False, False, True, False, False, False, True, False, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (16, 19)\n",
      "Kann Swar List: [[], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row16_col5_x213_y374_w12_h14.png'], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row16_col9_x273_y376_w14_h12.png'], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row16_col14_x399_y377_w6_h10.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row16_col15_x438_y377_w9_h10.png'], []]\n",
      "Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row18_col1_x116_y395_w15_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col2_x142_y400_w10_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col3_x162_y400_w11_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col4_x183_y395_w15_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col5_x215_y392_w14_h15.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col7_x239_y391_w15_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col8_x263_y399_w10_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col10_x284_y395_w10_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col11_x308_y399_w9_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col12_x338_y391_w13_h19.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col13_x372_y394_w9_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col14_x404_y394_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col15_x437_y394_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row18_col17_x468_y399_w12_h4.png']]\n",
      "Lyrics List: [['Analysis\\\\bilawal_dhamaar\\\\0_row19_col1_x115_y418_w15_h18.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col2_x141_y423_w7_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col3_x165_y423_w8_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col4_x183_y424_w11_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col5_x214_y420_w9_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col7_x237_y423_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col8_x263_y423_w7_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col10_x288_y424_w9_h14.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col11_x310_y423_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col12_x338_y423_w7_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col13_x367_y424_w13_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col14_x402_y417_w13_h22.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col15_x432_y423_w13_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col16_x463_y423_w8_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row19_col18_x478_y423_w5_h14.png']]\n",
      "Swar Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "Lyrics Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (22, 24)\n",
      "Kann Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row22_col1_x114_y477_w12_h14.png'], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row22_col6_x173_y478_w13_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row22_col7_x194_y481_w9_h10.png'], [], [], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row22_col14_x397_y477_w12_h13.png'], [], [], []]\n",
      "Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row23_col1_x115_y495_w14_h15.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col2_x137_y502_w10_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col4_x158_y502_w10_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col6_x179_y494_w14_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col8_x204_y493_w14_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col9_x239_y494_w15_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col10_x275_y502_w9_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col11_x306_y493_w15_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col12_x336_y503_w9_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col13_x364_y494_w15_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col14_x403_y494_w15_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col15_x424_y493_w8_h18.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col16_x442_y493_w15_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row23_col17_x467_y502_w12_h4.png']]\n",
      "Lyrics List: [['Analysis\\\\bilawal_dhamaar\\\\0_row24_col1_x115_y527_w13_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col3_x143_y526_w8_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col5_x164_y526_w8_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col6_x185_y527_w10_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col8_x209_y527_w9_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col9_x238_y527_w14_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col10_x274_y526_w8_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col11_x304_y527_w12_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col12_x337_y527_w8_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col13_x369_y527_w11_h15.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col14_x403_y522_w9_h21.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col15_x423_y526_w7_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col16_x449_y527_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row24_col17_x471_y526_w8_h12.png']]\n",
      "Swar Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "Lyrics Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (26, 27)\n",
      "Kann Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row26_col1_x113_y560_w13_h13.png'], [], [], [], [], [], [], [], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col12_x397_y560_w12_h13.png'], [], [], []]\n",
      "Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row26_col1_x114_y577_w15_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col2_x140_y576_w10_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col3_x161_y585_w9_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col4_x179_y558_w8_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col5_x185_y576_w10_h18.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col6_x208_y585_w10_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col7_x238_y585_w10_h5.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col8_x274_y577_w10_h16.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col9_x300_y561_w12_h31.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col10_x337_y585_w10_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col11_x368_y585_w12_h4.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col12_x402_y576_w15_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col13_x424_y575_w7_h18.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col14_x441_y575_w15_h18.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row26_col15_x463_y576_w15_h17.png']]\n",
      "Lyrics List: [['Analysis\\\\bilawal_dhamaar\\\\0_row27_col1_x114_y604_w13_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col2_x142_y609_w8_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col3_x160_y608_w8_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col5_x186_y610_w9_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col6_x210_y609_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col7_x238_y609_w8_h11.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col8_x274_y609_w10_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col9_x304_y609_w9_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col10_x341_y609_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col11_x372_y609_w7_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col12_x402_y603_w10_h18.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col13_x427_y609_w7_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col14_x446_y609_w9_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row27_col15_x470_y608_w8_h14.png']]\n",
      "Swar Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "Lyrics Articulation Checks: [False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (29, 33)\n",
      "Kann Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row29_col1_x112_y645_w10_h10.png'], [], [], [], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row29_col6_x233_y645_w10_h9.png'], [], ['Analysis\\\\bilawal_dhamaar\\\\0_row29_col8_x298_y646_w7_h10.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row29_col10_x332_y646_w9_h10.png'], [], [], [], [], []]\n",
      "Swar List: [['Analysis\\\\bilawal_dhamaar\\\\0_row30_col1_x113_y663_w11_h12.png'], ['Analysis\\\\bilawal_dhamaar_segmented\\\\0_row30_col2_x133_y658_w21_h12_seg1.png', 'Analysis\\\\bilawal_dhamaar_segmented\\\\0_row30_col2_x133_y658_w21_h12_seg2.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col3_x163_y657_w8_h19.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col4_x181_y658_w15_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col5_x203_y658_w15_h17.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col6_x239_y663_w10_h12.png'], ['Analysis\\\\bilawal_dhamaar_segmented\\\\0_row30_col7_x265_y658_w19_h14_seg1.png', 'Analysis\\\\bilawal_dhamaar_segmented\\\\0_row30_col7_x265_y658_w19_h14_seg2.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col8_x303_y662_w10_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col10_x336_y662_w11_h14.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row30_col11_x370_y667_w10_h4.png'], [], [], [], []]\n",
      "Lyrics List: [['Analysis\\\\bilawal_dhamaar\\\\0_row32_col1_x113_y688_w15_h16.png'], ['Analysis\\\\bilawal_dhamaar_segmented\\\\0_row32_col2_x138_y691_w13_h11_seg1.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col3_x167_y692_w7_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col4_x185_y692_w12_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col5_x207_y692_w10_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col6_x238_y691_w15_h13.png'], ['Analysis\\\\bilawal_dhamaar_segmented\\\\0_row32_col7_x270_y690_w13_h11_seg1.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col8_x304_y691_w8_h12.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col10_x334_y691_w14_h13.png'], ['Analysis\\\\bilawal_dhamaar\\\\0_row32_col11_x371_y691_w8_h12.png'], [], [], [], []]\n",
      "Swar Articulation Checks: [False, True, False, False, False, False, True, False, False, False, False, False, False, False]\n",
      "Lyrics Articulation Checks: [False, True, False, False, False, False, True, False, False, False, False, False, False, False]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.morphology import binary_erosion, binary_dilation, square\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "# Define the path to the folder to store segmented images\n",
    "segmented_folder_path = os.path.normpath('Analysis/bilawal_dhamaar_segmented')\n",
    "os.makedirs(segmented_folder_path, exist_ok=True)\n",
    "\n",
    "# Function to preprocess an image\n",
    "def preprocess_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 21, 5)\n",
    "    return thresh\n",
    "\n",
    "# Function to separate articulation in an image\n",
    "def separate_articulation(image):\n",
    "    processed_image = preprocess_image(image)\n",
    "    contours, _ = cv2.findContours(processed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if 10 < h < 21 and w > 25:\n",
    "            upper_part = image[:y, :]\n",
    "            if upper_part.shape[0] > 0:\n",
    "                return upper_part, True  # Return the upper part and a flag indicating segmentation was successful\n",
    "            break\n",
    "    \n",
    "    return image, False  # Return the original image and a flag indicating no segmentation\n",
    "\n",
    "# Function to segment a word into multiple images\n",
    "def segment_image(img):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Apply simple binary thresholding and invert the image\n",
    "    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Define structuring elements\n",
    "    structuring_element2 = np.ones((2, 2), dtype=bool)\n",
    "    structuring_element_erosion = square(3)\n",
    "\n",
    "    # Apply binary dilation to fill gaps\n",
    "    dilated = binary_dilation(binary, footprint=structuring_element2)\n",
    "\n",
    "    # Apply binary erosion to separate connected components\n",
    "    eroded = binary_erosion(dilated, footprint=structuring_element_erosion)\n",
    "    eroded = img_as_ubyte(eroded)  # Convert to uint8 for display purposes\n",
    "\n",
    "    # Perform vertical projection to find potential cut lines\n",
    "    vertical_projection = np.sum(eroded, axis=0)\n",
    "\n",
    "    # Find cut points by identifying valleys in the projection with heuristic\n",
    "    threshold = 0.15 * np.max(vertical_projection)\n",
    "    valleys = [x for x, y in enumerate(vertical_projection) if y < threshold]\n",
    "\n",
    "    # Apply heuristic: if two consecutive valleys are close, take the right one\n",
    "    cut_points = []\n",
    "    min_distance = 13\n",
    "    i = 0\n",
    "    while i < len(valleys) - 1:\n",
    "        if (valleys[i + 1] - valleys[i]) < min_distance:\n",
    "            cut_points.append(valleys[i + 1])\n",
    "            i += 2  # Skip the next valley since we took the right one\n",
    "        else:\n",
    "            cut_points.append(valleys[i])\n",
    "            i += 1\n",
    "    if i == len(valleys) - 1:\n",
    "        cut_points.append(valleys[i])  # Add the last valley if it's not processed\n",
    "\n",
    "    # Ensure no duplicate cut points and sort them\n",
    "    cut_points = sorted(set(cut_points))\n",
    "\n",
    "    # Separate the image at cut points\n",
    "    cut_images = []\n",
    "    start = 0\n",
    "    for cut_point in cut_points:\n",
    "        if cut_point - start > 10:  # Ensure segments are large enough\n",
    "            cut_image = img[:, start:cut_point]\n",
    "            cut_images.append(cut_image)\n",
    "            start = cut_point\n",
    "\n",
    "    # Add the last segment\n",
    "    cut_images.append(img[:, start:])\n",
    "\n",
    "    return cut_images\n",
    "\n",
    "# Function to merge segments based on height-to-width ratio\n",
    "def merge_segments(segments):\n",
    "    final_images = []\n",
    "    i = 0\n",
    "    while i < len(segments):\n",
    "        current_image = segments[i]\n",
    "        current_ratio = current_image.shape[0] / current_image.shape[1]\n",
    "\n",
    "        ratio_threshold = 1.8\n",
    "\n",
    "        if current_image.shape[0] > 35:\n",
    "            ratio_threshold = 2.9\n",
    "        \n",
    "        # If the ratio is greater than the threshold and it's the first segment\n",
    "        if current_ratio > ratio_threshold and i == 0:\n",
    "            # Merge with the next segment\n",
    "            if i + 1 < len(segments):\n",
    "                current_image = np.hstack((current_image, segments[i + 1]))\n",
    "                final_images.append(current_image)\n",
    "                i += 2\n",
    "            else:\n",
    "                final_images.append(current_image)\n",
    "                i += 1\n",
    "        # If two or more consecutive segments have a ratio greater than the threshold\n",
    "        elif i < len(segments) - 1 and (segments[i + 1].shape[0] / segments[i + 1].shape[1]) > ratio_threshold:\n",
    "            while i < len(segments) - 1 and (segments[i + 1].shape[0] / segments[i + 1].shape[1]) > ratio_threshold:\n",
    "                current_image = np.hstack((current_image, segments[i + 1]))\n",
    "                i += 1\n",
    "            final_images.append(current_image)\n",
    "            i += 1\n",
    "        # If the ratio is greater than the threshold and it's not the first segment\n",
    "        elif current_ratio > ratio_threshold and i != 0:\n",
    "            # Merge with the previous segment\n",
    "            if final_images:\n",
    "                final_images[-1] = np.hstack((final_images[-1], current_image))\n",
    "            else:\n",
    "                final_images.append(current_image)\n",
    "            i += 1\n",
    "        else:\n",
    "            final_images.append(current_image)\n",
    "            i += 1\n",
    "\n",
    "    return final_images\n",
    "\n",
    "# Function to process a single image, segment, and save the results in the provided folder\n",
    "def segment_word(image_path, output_folder):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return []\n",
    "    \n",
    "    # Segment the image\n",
    "    segmented_images = segment_image(img)\n",
    "    \n",
    "    # Merge segments based on height-to-width ratio\n",
    "    final_images = merge_segments(segmented_images)\n",
    "    \n",
    "    # Save the segmented images\n",
    "    image_base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    segmented_paths = []\n",
    "    for i, segmented_image in enumerate(final_images):\n",
    "        seg_image_path = os.path.normpath(os.path.join(output_folder, f'{image_base_name}_seg{i+1}.png'))\n",
    "        cv2.imwrite(seg_image_path, segmented_image)\n",
    "        segmented_paths.append(seg_image_path)\n",
    "    \n",
    "    return segmented_paths\n",
    "\n",
    "# Function to update lists based on segmentation\n",
    "def update_lists_with_segmentation(subgroup_results):\n",
    "    for subgroup_range, results in subgroup_results.items():\n",
    "        swar_list = results['swar_list']\n",
    "        lyrics_list = results['lyrics_list']\n",
    "        swar_articulation_checks = results['swar_articulation_checks']\n",
    "        lyrics_articulation_checks = results['lyrics_articulation_checks']\n",
    "        \n",
    "        # Apply articulation segmentation to swar row\n",
    "        for i in range(len(swar_list)):\n",
    "            if not swar_articulation_checks[i] and swar_list[i]:  # Check if articulation is False and the list is not empty\n",
    "                swar_image_path = swar_list[i][0]  # Get the image path\n",
    "                swar_image = cv2.imread(swar_image_path)  # Load the image\n",
    "                if swar_image is not None:\n",
    "                    segmented_image, is_segmented = separate_articulation(swar_image)\n",
    "                    if is_segmented:\n",
    "                        swar_articulation_checks[i] = True  # Update articulation check\n",
    "                        # Save the segmented image with the original name\n",
    "                        original_name = os.path.basename(swar_image_path)\n",
    "                        seg_image_path = os.path.normpath(os.path.join(segmented_folder_path, original_name))\n",
    "                        cv2.imwrite(seg_image_path, segmented_image)\n",
    "                        swar_list[i] = [seg_image_path]  # Update the list with the new image path\n",
    "        \n",
    "        # Apply articulation segmentation to lyrics row\n",
    "        for i in range(len(lyrics_list)):\n",
    "            if not lyrics_articulation_checks[i] and lyrics_list[i]:  # Check if articulation is False and the list is not empty\n",
    "                lyrics_image_path = lyrics_list[i][0]  # Get the image path\n",
    "                lyrics_image = cv2.imread(lyrics_image_path)  # Load the image\n",
    "                if lyrics_image is not None:\n",
    "                    segmented_image, is_segmented = separate_articulation(lyrics_image)\n",
    "                    if is_segmented:\n",
    "                        lyrics_articulation_checks[i] = True  # Update articulation check\n",
    "                        # Save the segmented image with the original name\n",
    "                        original_name = os.path.basename(lyrics_image_path)\n",
    "                        seg_image_path = os.path.normpath(os.path.join(segmented_folder_path, original_name))\n",
    "                        cv2.imwrite(seg_image_path, segmented_image)\n",
    "                        lyrics_list[i] = [seg_image_path]  # Update the list with the new image path\n",
    "        \n",
    "        # Apply word segmentation to swar row\n",
    "        for i in range(len(swar_list)):\n",
    "            if swar_articulation_checks[i] and swar_list[i]:  # Check if articulation is True and the list is not empty\n",
    "                swar_image_path = swar_list[i][0]  # Get the image path\n",
    "                segmented_paths = segment_word(swar_image_path, segmented_folder_path)\n",
    "                if segmented_paths:\n",
    "                    swar_list[i] = segmented_paths  # Update the list with segmented image paths\n",
    "        \n",
    "        # Apply word segmentation to lyrics row\n",
    "        for i in range(len(lyrics_list)):\n",
    "            if lyrics_articulation_checks[i] and lyrics_list[i]:  # Check if articulation is True and the list is not empty\n",
    "                lyrics_image_path = lyrics_list[i][0]  # Get the image path\n",
    "                segmented_paths = segment_word(lyrics_image_path, segmented_folder_path)\n",
    "                if segmented_paths:\n",
    "                    lyrics_list[i] = segmented_paths  # Update the list with segmented image paths\n",
    "        \n",
    "        # Update the results\n",
    "        subgroup_results[subgroup_range]['swar_list'] = swar_list\n",
    "        subgroup_results[subgroup_range]['lyrics_list'] = lyrics_list\n",
    "        subgroup_results[subgroup_range]['swar_articulation_checks'] = swar_articulation_checks\n",
    "        subgroup_results[subgroup_range]['lyrics_articulation_checks'] = lyrics_articulation_checks\n",
    "\n",
    "# Example usage\n",
    "update_lists_with_segmentation(subgroup_results)\n",
    "\n",
    "# Print the updated results for each subgroup\n",
    "for subgroup_range, results in subgroup_results.items():\n",
    "    print(f\"Subgroup Range: {subgroup_range}\")\n",
    "    print(f\"Kann Swar List: {results['kann_swar_list']}\")\n",
    "    print(f\"Swar List: {results['swar_list']}\")\n",
    "    print(f\"Lyrics List: {results['lyrics_list']}\")\n",
    "    print(f\"Swar Articulation Checks: {results['swar_articulation_checks']}\")\n",
    "    print(f\"Lyrics Articulation Checks: {results['lyrics_articulation_checks']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Subgroup Range: (4, 7)\n",
      "Predicted Swar List: [[], [], [], [], [], [], [], [], [], [], [], ['dha'], ['ga'], ['-']]\n",
      "Predicted Kann Swar List: [[], [], [], [], [], [], [], [], [], [], [], ['pa'], ['pa'], []]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (7, 8)\n",
      "Predicted Swar List: [['pa'], ['-'], ['ni'], ['ni'], [\"saa'\"], ['-'], ['-'], ['ni'], ['ni'], [\"saa'\"], ['-'], [\"re'\"], [\"saa'\"], ['-']]\n",
      "Predicted Kann Swar List: [[], [], [\"saa'\"], [], [], [], [], [], ['dha'], [], [], [\"saa'\"], [], []]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (10, 14)\n",
      "Predicted Swar List: [['dha'], ['dha,', 'ni-'], ['pa'], ['-'], ['ga'], ['ga'], ['ma#', 're'], ['ga'], ['ma'], ['pa'], ['saa', '|'], ['ga'], ['re'], ['-']]\n",
      "Predicted Kann Swar List: [[\"saa'\"], [], [], [], ['pa'], ['pa'], [], ['ma'], [], [], [], [], [], []]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (16, 19)\n",
      "Predicted Swar List: [['saa'], ['-'], ['-'], ['saa'], ['saa'], [\"saa'\"], ['-'], ['dha'], ['-'], ['ni-'], ['pa'], ['dha'], ['ga'], ['-']]\n",
      "Predicted Kann Swar List: [[], [], [], [], ['ni'], [], [], ['saa'], [], [], [], ['pa'], ['dha'], []]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (22, 24)\n",
      "Predicted Swar List: [['saa'], ['-'], ['-'], ['ni'], ['ni'], [\"saa'\"], ['-'], [\"saa'\"], ['-'], [\"saa'\"], [\"saa'\"], [\"re'\"], [\"saa'\"], ['-']]\n",
      "Predicted Kann Swar List: [['ni'], [], [], [\"saa'\"], ['dha'], [], [], [], [], [], ['ni'], [], [], []]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (26, 27)\n",
      "Predicted Swar List: [[\"saa'\"], [\"ga'\"], ['-'], [\"re'\"], [\"ga'\"], ['-'], ['-'], [\"ma#'\"], ['pa,'], ['-'], ['-'], [\"saa'\"], [\"re'\"], [\"saa'\"], [\"saa'\"]]\n",
      "Predicted Kann Swar List: [['ni'], [], [], [], [], [], [], [], [], [], [], ['ni'], [], [], []]\n",
      "--------------------------------------------------------------------------------\n",
      "Subgroup Range: (29, 33)\n",
      "Predicted Swar List: [['dha'], [\"saa'\", 'ni'], [\"re'\"], [\"saa'\"], [\"saa'\"], ['dha'], ['ni-', \"pa'\"], ['dha'], ['ga'], ['-'], [], [], [], []]\n",
      "Predicted Kann Swar List: [['saa'], [], [], [], [], ['saa'], [], ['pa'], ['dha'], [], [], [], [], []]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('cnn_recognizer_music_15_v1.h5')\n",
    "\n",
    "# Preprocess the input image\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Unable to read image at path: {image_path}\")\n",
    "    image = cv2.resize(image, (32, 32))  # Resize to match the model's input size\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# Pass the image through the model and get predictions\n",
    "def predict_class(image_path):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    predictions = model.predict(preprocessed_image)\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)\n",
    "    max_probability = np.max(predictions, axis=1)\n",
    "    return predicted_class_index[0], max_probability[0]\n",
    "\n",
    "# Define the classes\n",
    "# classes = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \n",
    "#            \"\\u0951\", \"\\u0951\", \"\\u0951\", \"\\u0951\", \"\\u0951\", \"\\u0951\", \"\\u0951\", \"\\u0951\", \"'\", \n",
    "#            \"\\u093C\", \"\\u093C\", \"\\u093C\", \"\\u093C\", \"\\u093C\", \"\\u093C\", \"\\u093C\", \n",
    "#            \")\", \",\", \"-\", \"\", \"O\", \"(\", \"^^\", \"X\", \"\", \"\", \"|\", \"<_>\"]\n",
    "\n",
    "classes = [\"saa\", \"re\", \"ga\", \"ma\", \"pa\", \"dha\", \"ni\", \"re-\", \"ga-\", \"dha-\", \"ni-\", \"ma#\", \n",
    "           \"saa'\", \"re'\", \"ga'\", \"ma'\", \"pa'\", \"dha'\", \"re-'\", \"ga-'\", \"ma#'\", \n",
    "           \"ma,\", \"ma#,\", \"pa,\", \"dha-,\", \"dha,\", \"ni-,\", \"ni,\", \n",
    "           \")\", \",\", \"-\", \"\", \"O\", \"(\", \"^^\", \"X\", \"\", \"\", \"|\", \"<_>\"]\n",
    "\n",
    "classes = [\"c\", \"d\", \"e\", \"f\", \"g\", \"a\", \"b\", \"d-\", \"e-\", \"a-\", \"b-\", \"f#\", \n",
    "           \"cc\", \"dd\", \"ee\", \"ff\", \"gg\", \"aa\", \"dd-\", \"ee-\", \"ff#\", \n",
    "           \"F\", \"F#\", \"G\", \"A-\", \"A\", \"B-\", \"B\", \n",
    "           \")\", \",\", \"-\", \"\", \"O\", \"(\", \"^^\", \"X\", \"\", \"\", \"|\", \"<_>\"]\n",
    "\n",
    "# Function to generate new lists with predicted class names\n",
    "def generate_predicted_lists(subgroup_results):\n",
    "    predicted_results = {}\n",
    "    \n",
    "    for subgroup_range, results in subgroup_results.items():\n",
    "        # Initialize new lists for predicted class names\n",
    "        predicted_swar_list = []\n",
    "        predicted_kann_swar_list = []  # Add this if you have kann_swar_list\n",
    "        \n",
    "        # Predict class names for swar_list\n",
    "        for image_paths in results['swar_list']:\n",
    "            if image_paths:  # Check if the list is not empty\n",
    "                predicted_classes = []\n",
    "                for image_path in image_paths:\n",
    "                    predicted_class_index, _ = predict_class(image_path)\n",
    "                    predicted_class_name = classes[predicted_class_index]\n",
    "                    predicted_classes.append(predicted_class_name)\n",
    "                predicted_swar_list.append(predicted_classes)\n",
    "            else:\n",
    "                predicted_swar_list.append([])  # Append empty list for empty entries\n",
    "        \n",
    "        # Predict class names for kann_swar_list (if applicable)\n",
    "        for image_paths in results['kann_swar_list']:\n",
    "            if image_paths:  # Check if the list is not empty\n",
    "                predicted_classes = []\n",
    "                for image_path in image_paths:\n",
    "                    predicted_class_index, _ = predict_class(image_path)\n",
    "                    predicted_class_name = classes[predicted_class_index]\n",
    "                    predicted_classes.append(predicted_class_name)\n",
    "                predicted_kann_swar_list.append(predicted_classes)\n",
    "            else:\n",
    "                predicted_kann_swar_list.append([])  # Append empty list for empty entries\n",
    "        \n",
    "        # Store the predicted results for this subgroup\n",
    "        predicted_results[subgroup_range] = {\n",
    "            'predicted_swar_list': predicted_swar_list,\n",
    "            'predicted_kann_swar_list': predicted_kann_swar_list  \n",
    "        }\n",
    "    \n",
    "    return predicted_results\n",
    "\n",
    "# Example usage\n",
    "# Assuming subgroup_results is the dictionary you provided\n",
    "predicted_results = generate_predicted_lists(subgroup_results)\n",
    "\n",
    "# Print the predicted results\n",
    "for subgroup_range, results in predicted_results.items():\n",
    "    print(f\"Subgroup Range: {subgroup_range}\")\n",
    "    print(f\"Predicted Swar List: {results['predicted_swar_list']}\")\n",
    "    print(f\"Predicted Kann Swar List: {results['predicted_kann_swar_list']}\") \n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Row 9 Predictions: ['', 'X', '', 'O']\n",
      "Row 15 Predictions: ['', 'X', '', 'O']\n",
      "Row 20 Predictions: ['', 'X', '', '']\n",
      "Row 25 Predictions: ['X', '', 'O', '']\n",
      "Row 28 Predictions: ['X', '', 'O', '']\n",
      "Row 34 Predictions: ['X', '', 'O']\n"
     ]
    }
   ],
   "source": [
    "def predict_sam_taalis_rows(row_col_images, rows_to_predict):\n",
    "    \"\"\"\n",
    "    Predicts the class names for specific rows (sam and taalis) and returns a dictionary\n",
    "    where each key is a row number and the value is a list of predicted class names.\n",
    "    \"\"\"\n",
    "    predicted_results = {}\n",
    "\n",
    "    for row_num in rows_to_predict:\n",
    "        if row_num in row_col_images:  # Check if the row exists in the dictionary\n",
    "            # Initialize a list to store predicted class names for this row\n",
    "            predicted_classes = []\n",
    "\n",
    "            # Get the columns for this row\n",
    "            columns = sorted(row_col_images[row_num].keys())\n",
    "\n",
    "            # Loop through each column in the row\n",
    "            for col_num in columns:\n",
    "                # Get the list of images for this row and column\n",
    "                images = row_col_images[row_num][col_num]\n",
    "\n",
    "                # Predict the class for each image in the column\n",
    "                for image in images:\n",
    "                    _, _, _, _, image_path = image  # Extract the image path\n",
    "                    predicted_class_index, _ = predict_class(image_path)  # Predict the class\n",
    "                    predicted_class_name = classes[predicted_class_index]  # Get the class name\n",
    "                    predicted_classes.append(predicted_class_name)\n",
    "\n",
    "            # Store the predicted results for this row\n",
    "            predicted_results[row_num] = predicted_classes\n",
    "        else:\n",
    "            # If the row doesn't exist, store an empty list\n",
    "            predicted_results[row_num] = []\n",
    "\n",
    "    return predicted_results\n",
    "\n",
    "# Define the rows to predict\n",
    "sam_taalis_rows = [9, 15, 20, 25, 28, 34]\n",
    "\n",
    "# Predict the rows\n",
    "sam_taalis_predictions = predict_sam_taalis_rows(row_col_images, sam_taalis_rows)\n",
    "\n",
    "# Print the predicted results\n",
    "for row_num, predictions in sam_taalis_predictions.items():\n",
    "    print(f\"Row {row_num} Predictions: {predictions}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
