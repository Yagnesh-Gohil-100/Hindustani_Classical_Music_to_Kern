{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import fitz\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to remove noise\n",
    "    blurred = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "\n",
    "    # Apply adaptive thresholding to enhance contrast\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 21, 5)\n",
    "\n",
    "    return thresh\n",
    "\n",
    "def enlarge_image(image, scale_factor=3):\n",
    "    # Enlarge the image with Lanczos interpolation\n",
    "    enlarged_image = cv2.resize(image, (0, 0), fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LANCZOS4)\n",
    "    \n",
    "    return enlarged_image\n",
    "\n",
    "def enhance_quality(image):\n",
    "    # Sharpen the image\n",
    "    sharpened = cv2.filter2D(image, -1, np.array([[-1, -1, -1],\n",
    "                                                  [-1,  9, -1],\n",
    "                                                  [-1, -1, -1]]))\n",
    "    \n",
    "    # Denoise the image\n",
    "    denoised = cv2.fastNlMeansDenoisingColored(sharpened, None, 10, 10, 7, 21)\n",
    "    \n",
    "    return denoised\n",
    "\n",
    "\n",
    "def extract_alphabets(pdf_path, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    x_coords = []\n",
    "    y_coords = []\n",
    "\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "        page_image = page.get_pixmap()\n",
    "        np_page_image = np.frombuffer(page_image.samples, dtype=np.uint8).reshape((page_image.height, page_image.width, page_image.n))\n",
    "\n",
    "        # Preprocess image\n",
    "        processed_image = preprocess_image(np_page_image)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(processed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for contour in contours:\n",
    "            # Get bounding box of each contour\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            x_coords.append(x)\n",
    "            y_coords.append(y)\n",
    "\n",
    "            # Crop, enlarge, and enhance quality of region containing alphabet\n",
    "            alphabet_region = np_page_image[y:y+h, x:x+w]\n",
    "            enlarged_region = enlarge_image(alphabet_region)\n",
    "            enhanced_region = enhance_quality(enlarged_region)\n",
    "\n",
    "            # Save region containing alphabet\n",
    "            alphabet_image = Image.fromarray(enhanced_region)\n",
    "            alphabet_image.save(f\"{output_folder}/alphabet_{page_num}_{x}_{y}.png\")\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"semi_book.pdf\"\n",
    "output_folder = \"segmented_data\"\n",
    "extract_alphabets(pdf_path, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
